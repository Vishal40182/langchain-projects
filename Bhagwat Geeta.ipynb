{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a5bdb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain tiktoken pypdf faiss-gpu\n",
    "# ! pip install transformers InstructorEmbedding sentence_transformers\n",
    "# ! pip install accelerate bitsandbytes xformers einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd28dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 3060 (UUID: GPU-cb28bdfd-369b-2760-c83c-ec4bb5b3e433)\r\n",
      "GPU 1: NVIDIA GeForce RTX 3060 (UUID: GPU-09417bfe-6780-ab5d-e066-08ff6cd5b8bf)\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b50edaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain: 0.0.315\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import textwrap\n",
    "import time\n",
    "\n",
    "import langchain\n",
    "\n",
    "# loaders\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "# splits\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# prompts\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "# vector stores\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# models\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "# retrievers\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "print('LangChain:', langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b04870b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['geeta/geeta.pdf']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(r\"geeta/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "293f4631",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    model_name = 'wizardlm'\n",
    "    temperature = 0.25,\n",
    "    top_p = 0.95\n",
    "    repetition_penalty = 1.15\n",
    "    \n",
    "    split_chunk_size =  800\n",
    "    split_overlap = 0\n",
    "    \n",
    "    embeddings_model_repo = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "    \n",
    "    k = 3\n",
    "    \n",
    "    PDFs_path = \"geeta/\"\n",
    "    Embeddings_path = \"faiss_index_hp/\"\n",
    "    Persist_directory = \"./geeta-vectordb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fbd93a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model = CFG.model_name):\n",
    "    \n",
    "    print('\\nDownloading model: ', model, '\\n\\n')\n",
    "    \n",
    "    if model == 'wizardlm':\n",
    "        model_repo = 'TheBloke/wizardLM-7B-HF'\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
    "        \n",
    "        model = AutoModelForCausalLM.from_pretrained(model_repo,\n",
    "                                                     load_in_4bit=True,\n",
    "                                                     device_map='auto',\n",
    "                                                     torch_dtype=torch.float16,\n",
    "                                                     low_cpu_mem_usage=True\n",
    "                                                    )\n",
    "        \n",
    "        max_len = 1024\n",
    "        \n",
    "    elif model == 'bloom':\n",
    "        model_repo = 'bigscience/bloom-7b1'\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_repo,\n",
    "            load_in_4bit=True,\n",
    "            device_map='auto',\n",
    "            torch_dtype=torch.float16,\n",
    "            low_cpu_mem_usage=True,\n",
    "        )\n",
    "        \n",
    "        max_len = 1024\n",
    "        \n",
    "    elif model == 'falcon':\n",
    "        model_repo = 'h2oai/h2ogpt-gm-oasst1-en-2048-falcon-7b-v2'\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_repo,\n",
    "            load_in_4bit=True,\n",
    "            device_map='auto',\n",
    "            torch_dtype=torch.float16,\n",
    "            low_cpu_mem_usage=True,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        max_len = 1024\n",
    "\n",
    "    else:\n",
    "        print(\"Not implemented model (tokenizer and backbone)\")\n",
    "\n",
    "    return tokenizer, model, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcd7b645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading model:  wizardlm \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c47edccb184bd48202d65a82abb2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 s, sys: 5.84 s, total: 17.8 s\n",
      "Wall time: 55.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer, model, max_len = get_model(model=CFG.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e37713f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32001, 4096, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32001, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e098eec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.embed_tokens': 0,\n",
       " 'model.layers.0': 0,\n",
       " 'model.layers.1': 0,\n",
       " 'model.layers.2': 0,\n",
       " 'model.layers.3': 0,\n",
       " 'model.layers.4': 0,\n",
       " 'model.layers.5': 0,\n",
       " 'model.layers.6': 0,\n",
       " 'model.layers.7': 0,\n",
       " 'model.layers.8': 0,\n",
       " 'model.layers.9': 0,\n",
       " 'model.layers.10': 0,\n",
       " 'model.layers.11': 0,\n",
       " 'model.layers.12': 0,\n",
       " 'model.layers.13': 1,\n",
       " 'model.layers.14': 1,\n",
       " 'model.layers.15': 1,\n",
       " 'model.layers.16': 1,\n",
       " 'model.layers.17': 1,\n",
       " 'model.layers.18': 1,\n",
       " 'model.layers.19': 1,\n",
       " 'model.layers.20': 1,\n",
       " 'model.layers.21': 1,\n",
       " 'model.layers.22': 1,\n",
       " 'model.layers.23': 1,\n",
       " 'model.layers.24': 1,\n",
       " 'model.layers.25': 1,\n",
       " 'model.layers.26': 1,\n",
       " 'model.layers.27': 1,\n",
       " 'model.layers.28': 1,\n",
       " 'model.layers.29': 1,\n",
       " 'model.layers.30': 1,\n",
       " 'model.layers.31': 1,\n",
       " 'model.norm': 1,\n",
       " 'lm_head': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hf_device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7748a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    task = \"text-generation\",\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    pad_token_id = tokenizer.eos_token_id,\n",
    "    max_length = max_len,\n",
    "    temperature = CFG.temperature,\n",
    "    top_p = CFG.top_p,\n",
    "    repetition_penalty = CFG.repetition_penalty\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline = pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b921837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7fcd70ba10c0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffd1ebb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "1. Fire Potion: This potion gives the drinker the ability to control fire. It is made by boiling a combination of flammable ingredients together for several hours until it turns into a deep red liquid with a strong, pungent odor. When consumed, the drinker's body becomes surrounded in an aura of fire, making them nearly invulnerable to harm. However, the downside is that the user's emotions become highly unstable, causing them to lash out violently at anything or anyone who threatens their personal space.\n",
      "2. Ice Potion: This potion freezes whatever it comes into contact with. It is made by combining a mixture of ice and water with a few drops of a rare plant extract. When drunk, the potion causes the drinker's skin to turn blue and their breath to fog up in the air. The user can then use this power to create an icy shield or even freeze opponents in place. However, like the fire potion, the user's emotions become highly unstable, causing them to become extremely cold and distant towards others.\n",
      "3. Healing Potion: This potion has the power to heal any physical wound or illness. It is made from a combination of rare herbs and flowers that are boiled together for several days. When drunk, the potion restores the body's natural balance and energy, healing any injuries or diseases. However, the downside is that the user must be careful not to overindulge, as the potion can cause dizziness and nausea if too much is consumed.\n",
      "4. Invisibility Potion: This potion makes the drinker invisible to everyone around them. It is made by brewing a combination of plants and herbs together for several weeks until it turns into a clear, colorless liquid. When drunk, the user becomes invisible to all forms of sight and sound, allowing them to sneak past enemies undetected. However, the downside is that the user cannot see or hear anything either, making it difficult to navigate through dangerous situations.\n",
      "5. Size-Changing Potion: This potion allows the drinker to change their size at will. It is made by boiling a combination of plants and herbs together for several months until it turns into a thick, brown syrup. When drunk, the user can choose to grow or shrink to any size they desire. However, the downside is that the potion can have adverse effects on the user's internal organs if used excessively, causing them to swell or shrivel up.\n",
      "CPU times: user 1min 36s, sys: 27.5 s, total: 2min 3s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### testing model, not using the harry potter books yet\n",
    "### answer is not necessarily related to harry potter\n",
    "query = \"Give me 5 examples of cool potions and explain what they do\"\n",
    "print(llm(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "913f4c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:10<00:00, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.15 s, sys: 337 ms, total: 8.49 s\n",
      "Wall time: 10.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    CFG.PDFs_path,\n",
    "    glob = './*.pdf',\n",
    "    loader_cls=PyPDFLoader,\n",
    "    show_progress=True,\n",
    "    use_multithreading=True\n",
    "    )\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15ab8036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1051 pages in total.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We have {len(documents)} pages in total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e979c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copyright © 1998 The Bhaktivedanta Book Trust Int'l. All Rights Reserved.eka-stham —situated in one; anupaçyati —one tries to see through authority;\n",
      "tataù eva —thereafter; ca—also; vistäram —the expansion; brahma —the\n",
      "Absolute; sampadyate —he attains; tadä—at th at time.\n",
      "TRANSLATION\n",
      "When a sensible man ceases to s ee different identities due to different\n",
      "material bodies and he sees how beings  are expanded everywhere, he attains to\n",
      "the Brahman conception.\n",
      "PURPORT\n",
      "When one can see that the various bodies  of living entities arise due to the\n",
      "different desires of the individual soul and do not actually belong to the soul\n",
      "itself, one actually sees. In the material conception of life, we find someone a\n",
      "demigod, someone a  human being, a dog, a cat, etc. This is material vision, not\n",
      "actual vision. This material differentiat ion is due to a material conception of\n",
      "life. After the destruction of the material body, the spirit soul is one. The spirit\n",
      "soul, due to contact with mat erial nature, gets different types of bodies. When\n",
      "one can see this, he attains spiritual vision; thus being freed from\n",
      "differentiations like man, animal, big, low, etc., one becomes purified in his\n",
      "consciousness and able to develop Kåñëa consciousness in his spiritual identity.\n",
      "How he then sees things will be explained in the next verse.\n",
      "TEXT  32\n",
      "ANaaidTvaiàGauR<aTvaTParMaaTMaaYaMaVYaYa\" )\n",
      "XarqrSQaae_iPa k-aENTaeYa Na k-raeiTa Na il/PYaTae )) 32 ))\n",
      "anäditvän nirguëatvät\n",
      "paramätmäyam avyayaù\n",
      "çaréra-stho ’pi kaunteya\n",
      "na karoti na lipyate\n"
     ]
    }
   ],
   "source": [
    "print(documents[800].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47f1452b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have craeted 2774 chunks from 1051 pages\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = CFG.split_chunk_size,\n",
    "    chunk_overlap = CFG.split_overlap\n",
    "    )\n",
    "\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f'We have craeted {len(texts)} chunks from {len(documents)} pages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64a02f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "CPU times: user 7.99 s, sys: 188 ms, total: 8.17 s\n",
      "Wall time: 8.05 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# ### download embeddings model\n",
    "# embeddings = HuggingFaceInstructEmbeddings(\n",
    "#     model_name = CFG.embeddings_model_repo,\n",
    "#     model_kwargs = {\"device\": \"cuda\"}\n",
    "# )\n",
    "\n",
    "# ### create embeddings and DB\n",
    "# vectordb = FAISS.from_documents(\n",
    "#     documents = texts, \n",
    "#     embedding = embeddings\n",
    "# )\n",
    "\n",
    "# ### persist vector database\n",
    "# vectordb.save_local(\"faiss_index_hp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1efb3ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "CPU times: user 312 ms, sys: 77.3 ms, total: 389 ms\n",
      "Wall time: 215 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### download embeddings model\n",
    "embeddings = HuggingFaceInstructEmbeddings(\n",
    "    model_name = CFG.embeddings_model_repo,\n",
    "    model_kwargs = {\"device\": \"cuda\"}\n",
    ")\n",
    "\n",
    "### load vector DB embeddings\n",
    "vectordb = FAISS.load_local(\n",
    "    CFG.Embeddings_path,\n",
    "    embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea9bb5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='becomes phantasmagoria, and the senses  are like serpents’ teeth that are', metadata={'source': 'geeta/geeta.pdf', 'page': 994}),\n",
       " Document(page_content='also in Him, and because they are condit ioned, they are averse to serving the\\nSupreme Lord. Thus they are not allowed to enter into the spiritual sky. But\\nwith the coming forth of material nature these living entities are ag ain given a\\nchance to act in the material world an d prepare themselves to enter into the\\nspiritual world. That is the mystery of  this material creation. Actually the\\nliving entity is originally the spiritual part and parcel of the Supreme Lord, but\\ndue to his rebellious nature, he is conditioned within material nature. It really\\ndoes not matter how these living entities or superior entities of the Supreme\\nLord have come in contact with mate rial nature. The Supreme Personality of\\nGodhead knows, however, how and why this actually took place. In the', metadata={'source': 'geeta/geeta.pdf', 'page': 785}),\n",
       " Document(page_content='the principles of scripture but worship according to their own imagination? Are', metadata={'source': 'geeta/geeta.pdf', 'page': 907}),\n",
       " Document(page_content='these most confidential spiritual subjects , my illusion has now been dispelled.\\nPURPORT', metadata={'source': 'geeta/geeta.pdf', 'page': 657})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### test if vector DB was loaded correctly\n",
    "vectordb.similarity_search('magic creatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a35e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Give the answers as you are a spiritual speaker. Calmness should reflect in words.\n",
    "Use only the following pieces of context to answer the question at the end.\n",
    "You can make up the factual answer only if asked out of the context.\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template = prompt_template, \n",
    "    input_variables = [\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5513c618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_chain = LLMChain(prompt=PROMPT, llm=llm)\n",
    "# llm_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c30d855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs = {\"k\": CFG.k, \"search_type\" : \"similarity\"})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\", # map_reduce, map_rerank, stuff, refine\n",
    "    retriever = retriever, \n",
    "    chain_type_kwargs = {\"prompt\": PROMPT},\n",
    "    return_source_documents = True,\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "47608635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='a blissful eternal life of knowledge.\\nTEXT  24', metadata={'source': 'geeta/geeta.pdf', 'page': 790}),\n",
       " Document(page_content='the problems of life. In the Båhad-äraëyaka Upaniñad  (3.8.10 ) the perplexed\\nman is described as follows: yo vä etad akñaraà gärgy aviditväsmäû lokät praiti sa\\nkåpaëaù.  “He is a miser ly man who does not solve the problems of life as a\\nhuman and who thus quits this world like the cats and dogs, without\\nunderstanding the science of self-realization.” This human form of life is a\\nmost valuable asset for the living entity who can utilize i t for solving the\\nproblems of life; therefore, one who does not utilize this opportunity properly', metadata={'source': 'geeta/geeta.pdf', 'page': 100}),\n",
       " Document(page_content='factually, although the demons say that life is a dream, they are very expert in\\nenjoying this dream. And so, instead of acquiring knowledge, they become\\nmore and more implicated in their dreaml and. They conclude that as a child is\\nsimply the result of sexual intercourse between man and wom an, this world is', metadata={'source': 'geeta/geeta.pdf', 'page': 887})]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### testing MMR search\n",
    "question = \"What is the meaning of life?\"\n",
    "vectordb.max_marginal_relevance_search(question, k = CFG.k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "28665b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Copyright © 1998 The Bhaktivedanta Book Trust Int'l. All Rights Reserved.prahlädaç cäsmi daityänäà\\nkälaù kalayatäm aham\\nmågäëäà ca mågendro ’haà\\nvainateyaç ca pakñiëäm\\nSYNONYMS\\nprahlädaù —Prahläda; ca—also; asmi —I am; daityänäm —of the demons;\\nkälaù —time; kalayatäm —of subduers; aham —I am; mågäëäm —of animals;\\nca—and; måga-indraù —the lion; aham —I am; vainateyaù —Garuòa; ca—also;\\npakñiëäm —of birds.\\nTRANSLATION\\nAmong the Daitya demons I am the de voted Prahläda, among subduers I am\\ntime, among beasts I am the lion, and among birds I am Garuòa.\\nPURPORT\\nDiti and Aditi are two sisters. The sons  of Aditi are called Ädityas, and the\\nsons of Diti are called Daityas. All th e Ädityas are devotees of the Lord, and\\nall the Daityas are atheistic. Although Pr ahläda was born in the family of the\", metadata={'source': 'geeta/geeta.pdf', 'page': 642}),\n",
       " Document(page_content=\"Copyright © 1998 The Bhaktivedanta Book Trust Int'l. All Rights Reserved.Yakñas and Räkñasas; vasünäm —of the Vasus; pävakaù —fire; ca—also; asmi —I\\nam; meruù —Meru; çikhariëäm —of all mounta ins; aham —I am.\\nTRANSLATION\\nOf all the Rudras I am Lord Çiva, of the Yakñas and Räkñasas I am the Lord\\nof wealth [Kuvera], of the Vasus I am fire [Agni], and of mountains I am Meru.\\nPURPORT\\nThere are eleven Rudras, of whom Çaìk ara, Lord Çiva, is predominant. He\\nis the incarnation of the Supreme Lord in charge of the mode of ignorance in\\nthe universe. The leader of the Yakñas and Räkñasas is Kuvera, the master\\ntreasurer of the demigods, and he  is a representation of the Supreme Lord.\\nMeru is a mountain famed for its rich natural resources.\\nTEXT  24\", metadata={'source': 'geeta/geeta.pdf', 'page': 635}),\n",
       " Document(page_content=\"Copyright © 1998 The Bhaktivedanta Book Trust Int'l. All Rights Reserved.am the Himälayas.\\nPURPORT\\nBrahmä, the first living creature within the universe, created several sons\\nfor the propagation of various kinds of species. Among these sons, Bhågu is the\\nmost powerful sage. Of all the transcendental vibrations, the oà (oàkära )\\nrepresents Kåñëa. Of all s acrifices, the chanting of Hare Kåñëa, Hare Kåñëa,\\nKåñëa Kåñëa, Hare Hare/ Hare Räma, Hare Räma, Räma Räma, Hare Hare is\\nthe purest representation of Kåñëa.  Sometimes animal sacrifices are\\nrecommended, but in the sacrifice of Hare Kåñëa, Hare Kåñëa, there is no\\nquestion of violence. It is the simplest  and the purest. Whatever is sublime in\\nthe worlds is a representation of Kåñëa. Therefore the Himälayas, the greatest\", metadata={'source': 'geeta/geeta.pdf', 'page': 637})]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### testing similarity search\n",
    "question = \"Which are Hagrid's favorite animals?\"\n",
    "vectordb.similarity_search(question, k = CFG.k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "29829fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_text_preserve_newlines(text, width=700):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text\n",
    "\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    ans = wrap_text_preserve_newlines(llm_response['result'])\n",
    "    \n",
    "#     sources_used = ' \\n'.join(\n",
    "#         [\n",
    "#             source.metadata['source'].split('/')[-1][:-4] #+ ' - page: ' + str(source.metadata['page'])\n",
    "#             for source in llm_response['source_documents']\n",
    "#         ]\n",
    "#     )\n",
    "    \n",
    "    ans = ans #+ '\\n\\nSources: \\n' + sources_used\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b31d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_ans(query):\n",
    "    start = time.time()\n",
    "    llm_response = qa_chain(query)\n",
    "    ans = process_llm_response(llm_response)\n",
    "    end = time.time()\n",
    "\n",
    "    time_elapsed = int(round(end - start, 0))\n",
    "    time_elapsed_str = f'\\n\\nTime elapsed: {time_elapsed} s'\n",
    "    return ans + time_elapsed_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1dd0c230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wizardlm'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e822aead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32001, 4096, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32001, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4647df8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The meaning of life is to achieve self-realization or enlightenment through the process of yoga.\n",
      "\n",
      "Time elapsed: 3 s\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the meaning of life\"\n",
    "print(llm_ans(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc27c500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " By practicing detachment from material happiness and distress, and\n",
      "engaging oneself in devotional service to Lord Krishna.\n",
      "\n",
      "Time elapsed: 5 s\n"
     ]
    }
   ],
   "source": [
    "query = \"How to live a happy life?\"\n",
    "print(llm_ans(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a52a25f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I am not happy, but why?\n",
      "bot:   You have forgotten your true self and gotten lost in the world of\n",
      "material objects. To find happiness again, focus on your inner Self and let go\n",
      "of attachments to external things. Remember that all things are temporary and\n",
      "changing, so it's important to maintain equanimity and balance in life.\n",
      "\n",
      "Time elapsed: 9 s\n",
      "User: quit\n",
      "bot:   Refrain from doing something.\n",
      "\n",
      "Time elapsed: 2 s\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\n",
    "while query != \"quit\":\n",
    "    query = input(\"User: \")\n",
    "    print(\"bot: \",llm_ans(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d26c71d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c062e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c89d94b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
